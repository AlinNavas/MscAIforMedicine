{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:23:16.282458: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 17:23:16.302163: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-03 17:23:16.302188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-03 17:23:16.302789: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-03 17:23:16.306768: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 17:23:16.668183: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 699 images belonging to 10 classes.\n",
      "Found 151 images belonging to 10 classes.\n",
      "Found 149 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import swish, relu,selu\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "train_set= ('./Experiments/data_pre/mel_spectrogram_imgs/train')\n",
    "test_set=('./Experiments/data_pre/mel_spectrogram_imgs/test')\n",
    "val_set= ('./Experiments/data_pre/mel_spectrogram_imgs/val')\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(rescale= 1./255)\n",
    "val_datagen= image.ImageDataGenerator(rescale= 1./255)\n",
    "test_datagen= image.ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_set,batch_size =512 ,class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_set,shuffle=True,batch_size =128 ,class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_set,shuffle=True,batch_size =128 ,class_mode = 'categorical')\n",
    "x_train, y_train = next(train_generator)\n",
    "x_val,y_val= next(validation_generator)\n",
    "x_test, y_test = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'num_layers': 1, 'layer_size': 409, 'dropout_rate': 0.3736932106048628, 'use_batch_norm': True, 'activation': 'selu', 'learning_rate': 0.00010842262717330161}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:23:24.388288: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.407083: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.407108: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.410511: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.410550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.410564: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.660396: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.660424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.660428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-03 17:23:24.660444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-03 17:23:24.660457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5535 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:23:25.788841: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-05-03 17:23:25.879880: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-03 17:23:28.061516: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-03 17:23:28.534638: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f088821cdc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-03 17:23:28.534667: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-05-03 17:23:28.537843: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714753408.580579   13347 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 3.2459 - accuracy: 0.1035\n",
      "Epoch 1: val_loss improved from inf to 2.92777, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 6s 163ms/step - loss: 3.2459 - accuracy: 0.1035 - val_loss: 2.9278 - val_accuracy: 0.1016\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.9852 - accuracy: 0.1660\n",
      "Epoch 2: val_loss did not improve from 2.92777\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 2.9852 - accuracy: 0.1660 - val_loss: 2.9307 - val_accuracy: 0.1172\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.6811 - accuracy: 0.2070\n",
      "Epoch 3: val_loss improved from 2.92777 to 2.59323, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.6811 - accuracy: 0.2070 - val_loss: 2.5932 - val_accuracy: 0.2031\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.5743 - accuracy: 0.2129\n",
      "Epoch 4: val_loss improved from 2.59323 to 2.57719, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 2.5743 - accuracy: 0.2129 - val_loss: 2.5772 - val_accuracy: 0.2578\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.3422 - accuracy: 0.3066\n",
      "Epoch 5: val_loss did not improve from 2.57719\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 2.3422 - accuracy: 0.3066 - val_loss: 3.1756 - val_accuracy: 0.1953\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.2176 - accuracy: 0.3164\n",
      "Epoch 6: val_loss improved from 2.57719 to 2.37048, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.2176 - accuracy: 0.3164 - val_loss: 2.3705 - val_accuracy: 0.2188\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.0081 - accuracy: 0.3574\n",
      "Epoch 7: val_loss improved from 2.37048 to 2.16580, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 2.0081 - accuracy: 0.3574 - val_loss: 2.1658 - val_accuracy: 0.2812\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.9175 - accuracy: 0.3711\n",
      "Epoch 8: val_loss did not improve from 2.16580\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.9175 - accuracy: 0.3711 - val_loss: 2.3326 - val_accuracy: 0.2422\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.8026 - accuracy: 0.4102\n",
      "Epoch 9: val_loss did not improve from 2.16580\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.8026 - accuracy: 0.4102 - val_loss: 2.2062 - val_accuracy: 0.3125\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.7269 - accuracy: 0.4277\n",
      "Epoch 10: val_loss improved from 2.16580 to 1.65275, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.7269 - accuracy: 0.4277 - val_loss: 1.6528 - val_accuracy: 0.3984\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6627 - accuracy: 0.4844\n",
      "Epoch 11: val_loss did not improve from 1.65275\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.6627 - accuracy: 0.4844 - val_loss: 1.7251 - val_accuracy: 0.3750\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.6183 - accuracy: 0.5000\n",
      "Epoch 12: val_loss improved from 1.65275 to 1.63888, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 1.6183 - accuracy: 0.5000 - val_loss: 1.6389 - val_accuracy: 0.4375\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3923 - accuracy: 0.5410\n",
      "Epoch 13: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.3923 - accuracy: 0.5410 - val_loss: 1.8332 - val_accuracy: 0.3750\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4803 - accuracy: 0.5293\n",
      "Epoch 14: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.4803 - accuracy: 0.5293 - val_loss: 1.9250 - val_accuracy: 0.3984\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.4049 - accuracy: 0.5469\n",
      "Epoch 15: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.4049 - accuracy: 0.5469 - val_loss: 1.6894 - val_accuracy: 0.4141\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.3261 - accuracy: 0.5410\n",
      "Epoch 16: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.3261 - accuracy: 0.5410 - val_loss: 1.6903 - val_accuracy: 0.4141\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1772 - accuracy: 0.6113\n",
      "Epoch 17: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.1772 - accuracy: 0.6113 - val_loss: 1.7077 - val_accuracy: 0.4297\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.2078 - accuracy: 0.6191\n",
      "Epoch 18: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.2078 - accuracy: 0.6191 - val_loss: 2.3876 - val_accuracy: 0.3359\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1961 - accuracy: 0.5586\n",
      "Epoch 19: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.1961 - accuracy: 0.5586 - val_loss: 2.1393 - val_accuracy: 0.3828\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1243 - accuracy: 0.6309\n",
      "Epoch 20: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.1243 - accuracy: 0.6309 - val_loss: 1.9476 - val_accuracy: 0.4219\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0775 - accuracy: 0.6582\n",
      "Epoch 21: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.0775 - accuracy: 0.6582 - val_loss: 1.8705 - val_accuracy: 0.3594\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0463 - accuracy: 0.6504\n",
      "Epoch 22: val_loss did not improve from 1.63888\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.0463 - accuracy: 0.6504 - val_loss: 1.6532 - val_accuracy: 0.4375\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9235 - accuracy: 0.6758\n",
      "Epoch 23: val_loss improved from 1.63888 to 1.55425, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.9235 - accuracy: 0.6758 - val_loss: 1.5542 - val_accuracy: 0.5156\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0287 - accuracy: 0.6465\n",
      "Epoch 24: val_loss did not improve from 1.55425\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 1.0287 - accuracy: 0.6465 - val_loss: 1.6522 - val_accuracy: 0.4609\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.6855\n",
      "Epoch 25: val_loss did not improve from 1.55425\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.9237 - accuracy: 0.6855 - val_loss: 1.7247 - val_accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8388 - accuracy: 0.7266\n",
      "Epoch 26: val_loss did not improve from 1.55425\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.8388 - accuracy: 0.7266 - val_loss: 1.5772 - val_accuracy: 0.4922\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8410 - accuracy: 0.7109\n",
      "Epoch 27: val_loss improved from 1.55425 to 1.39070, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.8410 - accuracy: 0.7109 - val_loss: 1.3907 - val_accuracy: 0.5312\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7363\n",
      "Epoch 28: val_loss did not improve from 1.39070\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.7395 - accuracy: 0.7363 - val_loss: 1.7331 - val_accuracy: 0.4375\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.7500\n",
      "Epoch 29: val_loss did not improve from 1.39070\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.7347 - accuracy: 0.7500 - val_loss: 1.6200 - val_accuracy: 0.5078\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.7754\n",
      "Epoch 30: val_loss did not improve from 1.39070\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.6961 - accuracy: 0.7754 - val_loss: 2.3353 - val_accuracy: 0.3516\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6437 - accuracy: 0.7656\n",
      "Epoch 31: val_loss did not improve from 1.39070\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.6437 - accuracy: 0.7656 - val_loss: 1.6997 - val_accuracy: 0.4531\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7852\n",
      "Epoch 32: val_loss improved from 1.39070 to 1.37236, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.6307 - accuracy: 0.7852 - val_loss: 1.3724 - val_accuracy: 0.5469\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5912 - accuracy: 0.7754\n",
      "Epoch 33: val_loss did not improve from 1.37236\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.5912 - accuracy: 0.7754 - val_loss: 1.4930 - val_accuracy: 0.5078\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.8027\n",
      "Epoch 34: val_loss did not improve from 1.37236\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.5954 - accuracy: 0.8027 - val_loss: 1.7646 - val_accuracy: 0.4766\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5561 - accuracy: 0.8125\n",
      "Epoch 35: val_loss did not improve from 1.37236\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.5561 - accuracy: 0.8125 - val_loss: 2.1232 - val_accuracy: 0.4453\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5137 - accuracy: 0.8262\n",
      "Epoch 36: val_loss did not improve from 1.37236\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.5137 - accuracy: 0.8262 - val_loss: 1.8853 - val_accuracy: 0.4688\n",
      "Epoch 37/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5276 - accuracy: 0.8242\n",
      "Epoch 37: val_loss improved from 1.37236 to 1.36911, saving model to ./model_weights/VGG_r1_model_weights.h5\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.5276 - accuracy: 0.8242 - val_loss: 1.3691 - val_accuracy: 0.5391\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5006 - accuracy: 0.8105\n",
      "Epoch 38: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.5006 - accuracy: 0.8105 - val_loss: 1.8382 - val_accuracy: 0.4531\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.8730\n",
      "Epoch 39: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3985 - accuracy: 0.8730 - val_loss: 1.4836 - val_accuracy: 0.5547\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8633\n",
      "Epoch 40: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.4044 - accuracy: 0.8633 - val_loss: 1.5676 - val_accuracy: 0.5312\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.8750\n",
      "Epoch 41: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.3750 - accuracy: 0.8750 - val_loss: 1.4242 - val_accuracy: 0.5703\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.8828\n",
      "Epoch 42: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.3453 - accuracy: 0.8828 - val_loss: 1.4887 - val_accuracy: 0.5625\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8770\n",
      "Epoch 43: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3732 - accuracy: 0.8770 - val_loss: 1.7615 - val_accuracy: 0.5391\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8652\n",
      "Epoch 44: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3812 - accuracy: 0.8652 - val_loss: 1.7292 - val_accuracy: 0.5547\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8770\n",
      "Epoch 45: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3474 - accuracy: 0.8770 - val_loss: 1.4903 - val_accuracy: 0.5703\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3452 - accuracy: 0.8789\n",
      "Epoch 46: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.3452 - accuracy: 0.8789 - val_loss: 2.0139 - val_accuracy: 0.4766\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8750\n",
      "Epoch 47: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3403 - accuracy: 0.8750 - val_loss: 1.4159 - val_accuracy: 0.5547\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9062\n",
      "Epoch 48: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.2799 - accuracy: 0.9062 - val_loss: 1.4378 - val_accuracy: 0.6172\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9043\n",
      "Epoch 49: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.2924 - accuracy: 0.9043 - val_loss: 1.4628 - val_accuracy: 0.5781\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9258\n",
      "Epoch 50: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.2492 - accuracy: 0.9258 - val_loss: 1.7957 - val_accuracy: 0.5234\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9414\n",
      "Epoch 51: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.1848 - accuracy: 0.9414 - val_loss: 1.6641 - val_accuracy: 0.4688\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9141\n",
      "Epoch 52: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.2362 - accuracy: 0.9141 - val_loss: 2.0108 - val_accuracy: 0.4531\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.9199\n",
      "Epoch 53: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.2337 - accuracy: 0.9199 - val_loss: 1.9712 - val_accuracy: 0.4766\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9395\n",
      "Epoch 54: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.1918 - accuracy: 0.9395 - val_loss: 2.0242 - val_accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9375\n",
      "Epoch 55: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.2054 - accuracy: 0.9375 - val_loss: 1.8771 - val_accuracy: 0.4688\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.9395\n",
      "Epoch 56: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.1846 - accuracy: 0.9395 - val_loss: 1.6910 - val_accuracy: 0.5078\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9434\n",
      "Epoch 57: val_loss did not improve from 1.36911\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.1964 - accuracy: 0.9434 - val_loss: 1.6889 - val_accuracy: 0.5781\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "num_layers = best_params['num_layers']\n",
    "layer_size = best_params['layer_size']\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "use_batch_norm = best_params['use_batch_norm']\n",
    "activation = best_params['activation']\n",
    "learning_rate = best_params['learning_rate']\n",
    "\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "for layer in base_model.layers[:-1]: #####   modify the number of layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the VGG16 base model to the new model\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(layer_size, input_shape=(x_train.shape[1],)))\n",
    "model.add(Activation(activation))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "for _ in range(num_layers):\n",
    "    model.add(Dense(layer_size))\n",
    "    if use_batch_norm:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model with hyperparameters\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with hyperparameters\n",
    "csv_logger = CSVLogger('./logs/VGG_r1_training.csv')\n",
    "# Define the checkpoint callback\n",
    "checkpoint = ModelCheckpoint(filepath='./model_weights/VGG_r1_model_weights.h5', \n",
    "                             monitor='val_loss', \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True,\n",
    "                             mode='min',\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', min_delta=0.0001, restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=150, callbacks=[early_stopping,checkpoint,csv_logger], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6012/1491960095.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "/tmp/ipykernel_6012/1491960095.py:30: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the training and validation loss from the history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get the training and validation accuracy from the history\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('./img/VGG_r1_loss_plot.png')\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('./img/VGG_r1_accuracy_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 108ms/step - loss: 1.2634 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.26343834400177, 0.59375]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 105ms/step\n",
      "F1 Score: 0.5887786047189861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6012/3226880583.py:26: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "classes = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# Assuming you have the predicted labels and true labels\n",
    "y_pred = model.predict(x_test).argmax(axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "plt.savefig('./img/VGG_r1_confusion_matrix.png')\n",
    "# Print the F1 score\n",
    "print('F1 Score:', f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
