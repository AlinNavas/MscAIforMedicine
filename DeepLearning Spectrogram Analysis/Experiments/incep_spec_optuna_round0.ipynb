{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 09:57:30.697187: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-20 09:57:30.972691: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 09:57:30.972717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 09:57:31.021825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-20 09:57:31.126012: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 09:57:31.885335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set= ('./data_pre/spec_imgs/train')\n",
    "test_set=('./data_pre/spec_imgs/test')\n",
    "val_set= (r'./data_pre/spec_imgs/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rescale= 1./255)\n",
    "val_datagen= image.ImageDataGenerator(rescale= 1./255)\n",
    "test_datagen= image.ImageDataGenerator(rescale= 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 699 images belonging to 10 classes.\n",
      "Found 151 images belonging to 10 classes.\n",
      "Found 149 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_set,batch_size =512 ,class_mode = 'categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_set,shuffle=True,batch_size =128 ,class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_set,shuffle=True,batch_size =128 ,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(train_generator)\n",
    "x_val,y_val= next(validation_generator)\n",
    "x_test, y_test = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 13s 0us/step\n",
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]      0         []                            \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)          (None, None, None, 32)       864       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, None, None, 32)       96        ['conv2d_94[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_94 (Activation)  (None, None, None, 32)       0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)          (None, None, None, 32)       9216      ['activation_94[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, None, None, 32)       96        ['conv2d_95[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_95 (Activation)  (None, None, None, 32)       0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)          (None, None, None, 64)       18432     ['activation_95[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, None, None, 64)       192       ['conv2d_96[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_96 (Activation)  (None, None, None, 64)       0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, None, None, 64)       0         ['activation_96[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)          (None, None, None, 80)       5120      ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, None, None, 80)       240       ['conv2d_97[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_97 (Activation)  (None, None, None, 80)       0         ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)          (None, None, None, 192)      138240    ['activation_97[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, None, None, 192)      576       ['conv2d_98[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_98 (Activation)  (None, None, None, 192)      0         ['batch_normalization_98[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, None, None, 192)      0         ['activation_98[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)         (None, None, None, 64)       12288     ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, None, None, 64)       192       ['conv2d_102[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_102 (Activation  (None, None, None, 64)       0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)         (None, None, None, 48)       9216      ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)         (None, None, None, 96)       55296     ['activation_102[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, None, None, 48)       144       ['conv2d_100[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, None, None, 96)       288       ['conv2d_103[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_100 (Activation  (None, None, None, 48)       0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_103 (Activation  (None, None, None, 96)       0         ['batch_normalization_103[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_9 (Avera  (None, None, None, 192)      0         ['max_pooling2d_5[0][0]']     \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)          (None, None, None, 64)       12288     ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)         (None, None, None, 64)       76800     ['activation_100[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)         (None, None, None, 96)       82944     ['activation_103[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)         (None, None, None, 32)       6144      ['average_pooling2d_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, None, None, 64)       192       ['conv2d_99[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, None, None, 64)       192       ['conv2d_101[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, None, None, 96)       288       ['conv2d_104[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, None, None, 32)       96        ['conv2d_105[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_99 (Activation)  (None, None, None, 64)       0         ['batch_normalization_99[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " activation_101 (Activation  (None, None, None, 64)       0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_104 (Activation  (None, None, None, 96)       0         ['batch_normalization_104[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_105 (Activation  (None, None, None, 32)       0         ['batch_normalization_105[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)        (None, None, None, 256)      0         ['activation_99[0][0]',       \n",
      "                                                                     'activation_101[0][0]',      \n",
      "                                                                     'activation_104[0][0]',      \n",
      "                                                                     'activation_105[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)         (None, None, None, 64)       16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (None, None, None, 64)       192       ['conv2d_109[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_109 (Activation  (None, None, None, 64)       0         ['batch_normalization_109[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)         (None, None, None, 48)       12288     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)         (None, None, None, 96)       55296     ['activation_109[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, None, None, 48)       144       ['conv2d_107[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (None, None, None, 96)       288       ['conv2d_110[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_107 (Activation  (None, None, None, 48)       0         ['batch_normalization_107[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_110 (Activation  (None, None, None, 96)       0         ['batch_normalization_110[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_10 (Aver  (None, None, None, 256)      0         ['mixed0[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)         (None, None, None, 64)       16384     ['mixed0[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)         (None, None, None, 64)       76800     ['activation_107[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)         (None, None, None, 96)       82944     ['activation_110[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, None, None, 64)       16384     ['average_pooling2d_10[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, None, None, 64)       192       ['conv2d_106[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (None, None, None, 64)       192       ['conv2d_108[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (None, None, None, 96)       288       ['conv2d_111[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (None, None, None, 64)       192       ['conv2d_112[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_106 (Activation  (None, None, None, 64)       0         ['batch_normalization_106[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_108 (Activation  (None, None, None, 64)       0         ['batch_normalization_108[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_111 (Activation  (None, None, None, 96)       0         ['batch_normalization_111[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_112 (Activation  (None, None, None, 64)       0         ['batch_normalization_112[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)        (None, None, None, 288)      0         ['activation_106[0][0]',      \n",
      "                                                                     'activation_108[0][0]',      \n",
      "                                                                     'activation_111[0][0]',      \n",
      "                                                                     'activation_112[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, None, None, 64)       18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_116 (B  (None, None, None, 64)       192       ['conv2d_116[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_116 (Activation  (None, None, None, 64)       0         ['batch_normalization_116[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, None, None, 48)       13824     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, None, None, 96)       55296     ['activation_116[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (None, None, None, 48)       144       ['conv2d_114[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_117 (B  (None, None, None, 96)       288       ['conv2d_117[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_114 (Activation  (None, None, None, 48)       0         ['batch_normalization_114[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_117 (Activation  (None, None, None, 96)       0         ['batch_normalization_117[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_11 (Aver  (None, None, None, 288)      0         ['mixed1[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, None, None, 64)       18432     ['mixed1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, None, None, 64)       76800     ['activation_114[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, None, None, 96)       82944     ['activation_117[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, None, None, 64)       18432     ['average_pooling2d_11[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (None, None, None, 64)       192       ['conv2d_113[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_115 (B  (None, None, None, 64)       192       ['conv2d_115[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_118 (B  (None, None, None, 96)       288       ['conv2d_118[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_119 (B  (None, None, None, 64)       192       ['conv2d_119[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_113 (Activation  (None, None, None, 64)       0         ['batch_normalization_113[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_115 (Activation  (None, None, None, 64)       0         ['batch_normalization_115[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_118 (Activation  (None, None, None, 96)       0         ['batch_normalization_118[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_119 (Activation  (None, None, None, 64)       0         ['batch_normalization_119[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)        (None, None, None, 288)      0         ['activation_113[0][0]',      \n",
      "                                                                     'activation_115[0][0]',      \n",
      "                                                                     'activation_118[0][0]',      \n",
      "                                                                     'activation_119[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, None, None, 64)       18432     ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_121 (B  (None, None, None, 64)       192       ['conv2d_121[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_121 (Activation  (None, None, None, 64)       0         ['batch_normalization_121[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)         (None, None, None, 96)       55296     ['activation_121[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_122 (B  (None, None, None, 96)       288       ['conv2d_122[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_122 (Activation  (None, None, None, 96)       0         ['batch_normalization_122[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, None, None, 384)      995328    ['mixed2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, None, None, 96)       82944     ['activation_122[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_120 (B  (None, None, None, 384)      1152      ['conv2d_120[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_123 (B  (None, None, None, 96)       288       ['conv2d_123[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_120 (Activation  (None, None, None, 384)      0         ['batch_normalization_120[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_123 (Activation  (None, None, None, 96)       0         ['batch_normalization_123[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, None, None, 288)      0         ['mixed2[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)        (None, None, None, 768)      0         ['activation_120[0][0]',      \n",
      "                                                                     'activation_123[0][0]',      \n",
      "                                                                     'max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, None, None, 128)      98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_128 (B  (None, None, None, 128)      384       ['conv2d_128[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_128 (Activation  (None, None, None, 128)      0         ['batch_normalization_128[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, None, None, 128)      114688    ['activation_128[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_129 (B  (None, None, None, 128)      384       ['conv2d_129[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_129 (Activation  (None, None, None, 128)      0         ['batch_normalization_129[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, None, None, 128)      98304     ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, None, None, 128)      114688    ['activation_129[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_125 (B  (None, None, None, 128)      384       ['conv2d_125[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_130 (B  (None, None, None, 128)      384       ['conv2d_130[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_125 (Activation  (None, None, None, 128)      0         ['batch_normalization_125[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_130 (Activation  (None, None, None, 128)      0         ['batch_normalization_130[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, None, None, 128)      114688    ['activation_125[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)         (None, None, None, 128)      114688    ['activation_130[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_126 (B  (None, None, None, 128)      384       ['conv2d_126[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_131 (B  (None, None, None, 128)      384       ['conv2d_131[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_126 (Activation  (None, None, None, 128)      0         ['batch_normalization_126[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_131 (Activation  (None, None, None, 128)      0         ['batch_normalization_131[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (Aver  (None, None, None, 768)      0         ['mixed3[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, None, None, 192)      147456    ['mixed3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, None, None, 192)      172032    ['activation_126[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)         (None, None, None, 192)      172032    ['activation_131[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)         (None, None, None, 192)      147456    ['average_pooling2d_12[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_124 (B  (None, None, None, 192)      576       ['conv2d_124[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_127 (B  (None, None, None, 192)      576       ['conv2d_127[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_132 (B  (None, None, None, 192)      576       ['conv2d_132[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_133 (B  (None, None, None, 192)      576       ['conv2d_133[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_124 (Activation  (None, None, None, 192)      0         ['batch_normalization_124[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_127 (Activation  (None, None, None, 192)      0         ['batch_normalization_127[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_132 (Activation  (None, None, None, 192)      0         ['batch_normalization_132[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_133 (Activation  (None, None, None, 192)      0         ['batch_normalization_133[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)        (None, None, None, 768)      0         ['activation_124[0][0]',      \n",
      "                                                                     'activation_127[0][0]',      \n",
      "                                                                     'activation_132[0][0]',      \n",
      "                                                                     'activation_133[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)         (None, None, None, 160)      122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (None, None, None, 160)      480       ['conv2d_138[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_138 (Activation  (None, None, None, 160)      0         ['batch_normalization_138[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)         (None, None, None, 160)      179200    ['activation_138[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (None, None, None, 160)      480       ['conv2d_139[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_139 (Activation  (None, None, None, 160)      0         ['batch_normalization_139[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)         (None, None, None, 160)      122880    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)         (None, None, None, 160)      179200    ['activation_139[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (None, None, None, 160)      480       ['conv2d_135[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (None, None, None, 160)      480       ['conv2d_140[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_135 (Activation  (None, None, None, 160)      0         ['batch_normalization_135[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_140 (Activation  (None, None, None, 160)      0         ['batch_normalization_140[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)         (None, None, None, 160)      179200    ['activation_135[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, None, None, 160)      179200    ['activation_140[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (None, None, None, 160)      480       ['conv2d_136[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (None, None, None, 160)      480       ['conv2d_141[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_136 (Activation  (None, None, None, 160)      0         ['batch_normalization_136[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_141 (Activation  (None, None, None, 160)      0         ['batch_normalization_141[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (Aver  (None, None, None, 768)      0         ['mixed4[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)         (None, None, None, 192)      147456    ['mixed4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)         (None, None, None, 192)      215040    ['activation_136[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (None, None, None, 192)      215040    ['activation_141[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (None, None, None, 192)      147456    ['average_pooling2d_13[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_134 (B  (None, None, None, 192)      576       ['conv2d_134[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (None, None, None, 192)      576       ['conv2d_137[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (None, None, None, 192)      576       ['conv2d_142[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (None, None, None, 192)      576       ['conv2d_143[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_134 (Activation  (None, None, None, 192)      0         ['batch_normalization_134[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_137 (Activation  (None, None, None, 192)      0         ['batch_normalization_137[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_142 (Activation  (None, None, None, 192)      0         ['batch_normalization_142[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_143 (Activation  (None, None, None, 192)      0         ['batch_normalization_143[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)        (None, None, None, 768)      0         ['activation_134[0][0]',      \n",
      "                                                                     'activation_137[0][0]',      \n",
      "                                                                     'activation_142[0][0]',      \n",
      "                                                                     'activation_143[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (None, None, None, 160)      122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, None, None, 160)      480       ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_148 (Activation  (None, None, None, 160)      0         ['batch_normalization_148[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (None, None, None, 160)      179200    ['activation_148[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, None, None, 160)      480       ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_149 (Activation  (None, None, None, 160)      0         ['batch_normalization_149[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, None, None, 160)      122880    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (None, None, None, 160)      179200    ['activation_149[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, None, None, 160)      480       ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, None, None, 160)      480       ['conv2d_150[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_145 (Activation  (None, None, None, 160)      0         ['batch_normalization_145[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_150 (Activation  (None, None, None, 160)      0         ['batch_normalization_150[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, None, None, 160)      179200    ['activation_145[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)         (None, None, None, 160)      179200    ['activation_150[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, None, None, 160)      480       ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, None, None, 160)      480       ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_146 (Activation  (None, None, None, 160)      0         ['batch_normalization_146[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_151 (Activation  (None, None, None, 160)      0         ['batch_normalization_151[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (Aver  (None, None, None, 768)      0         ['mixed5[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, None, None, 192)      147456    ['mixed5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (None, None, None, 192)      215040    ['activation_146[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (None, None, None, 192)      215040    ['activation_151[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (None, None, None, 192)      147456    ['average_pooling2d_14[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, None, None, 192)      576       ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, None, None, 192)      576       ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, None, None, 192)      576       ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, None, None, 192)      576       ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_144 (Activation  (None, None, None, 192)      0         ['batch_normalization_144[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_147 (Activation  (None, None, None, 192)      0         ['batch_normalization_147[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_152 (Activation  (None, None, None, 192)      0         ['batch_normalization_152[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_153 (Activation  (None, None, None, 192)      0         ['batch_normalization_153[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)        (None, None, None, 768)      0         ['activation_144[0][0]',      \n",
      "                                                                     'activation_147[0][0]',      \n",
      "                                                                     'activation_152[0][0]',      \n",
      "                                                                     'activation_153[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_158 (B  (None, None, None, 192)      576       ['conv2d_158[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_158 (Activation  (None, None, None, 192)      0         ['batch_normalization_158[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (None, None, None, 192)      258048    ['activation_158[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_159 (B  (None, None, None, 192)      576       ['conv2d_159[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_159 (Activation  (None, None, None, 192)      0         ['batch_normalization_159[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)         (None, None, None, 192)      258048    ['activation_159[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_155 (B  (None, None, None, 192)      576       ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_160 (B  (None, None, None, 192)      576       ['conv2d_160[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_155 (Activation  (None, None, None, 192)      0         ['batch_normalization_155[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_160 (Activation  (None, None, None, 192)      0         ['batch_normalization_160[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (None, None, None, 192)      258048    ['activation_155[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)         (None, None, None, 192)      258048    ['activation_160[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_156 (B  (None, None, None, 192)      576       ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_161 (B  (None, None, None, 192)      576       ['conv2d_161[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_156 (Activation  (None, None, None, 192)      0         ['batch_normalization_156[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_161 (Activation  (None, None, None, 192)      0         ['batch_normalization_161[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " average_pooling2d_15 (Aver  (None, None, None, 768)      0         ['mixed6[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (None, None, None, 192)      147456    ['mixed6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (None, None, None, 192)      258048    ['activation_156[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)         (None, None, None, 192)      258048    ['activation_161[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)         (None, None, None, 192)      147456    ['average_pooling2d_15[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_154 (B  (None, None, None, 192)      576       ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_157 (B  (None, None, None, 192)      576       ['conv2d_157[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_162 (B  (None, None, None, 192)      576       ['conv2d_162[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_163 (B  (None, None, None, 192)      576       ['conv2d_163[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_154 (Activation  (None, None, None, 192)      0         ['batch_normalization_154[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_157 (Activation  (None, None, None, 192)      0         ['batch_normalization_157[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_162 (Activation  (None, None, None, 192)      0         ['batch_normalization_162[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_163 (Activation  (None, None, None, 192)      0         ['batch_normalization_163[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)        (None, None, None, 768)      0         ['activation_154[0][0]',      \n",
      "                                                                     'activation_157[0][0]',      \n",
      "                                                                     'activation_162[0][0]',      \n",
      "                                                                     'activation_163[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)         (None, None, None, 192)      147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_166 (B  (None, None, None, 192)      576       ['conv2d_166[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_166 (Activation  (None, None, None, 192)      0         ['batch_normalization_166[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)         (None, None, None, 192)      258048    ['activation_166[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_167 (B  (None, None, None, 192)      576       ['conv2d_167[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_167 (Activation  (None, None, None, 192)      0         ['batch_normalization_167[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)         (None, None, None, 192)      147456    ['mixed7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)         (None, None, None, 192)      258048    ['activation_167[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_164 (B  (None, None, None, 192)      576       ['conv2d_164[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_168 (B  (None, None, None, 192)      576       ['conv2d_168[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_164 (Activation  (None, None, None, 192)      0         ['batch_normalization_164[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_168 (Activation  (None, None, None, 192)      0         ['batch_normalization_168[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)         (None, None, None, 320)      552960    ['activation_164[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)         (None, None, None, 192)      331776    ['activation_168[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_165 (B  (None, None, None, 320)      960       ['conv2d_165[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_169 (B  (None, None, None, 192)      576       ['conv2d_169[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_165 (Activation  (None, None, None, 320)      0         ['batch_normalization_165[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_169 (Activation  (None, None, None, 192)      0         ['batch_normalization_169[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, None, None, 768)      0         ['mixed7[0][0]']              \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)        (None, None, None, 1280)     0         ['activation_165[0][0]',      \n",
      "                                                                     'activation_169[0][0]',      \n",
      "                                                                     'max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)         (None, None, None, 448)      573440    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_174 (B  (None, None, None, 448)      1344      ['conv2d_174[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_174 (Activation  (None, None, None, 448)      0         ['batch_normalization_174[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)         (None, None, None, 384)      491520    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)         (None, None, None, 384)      1548288   ['activation_174[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_171 (B  (None, None, None, 384)      1152      ['conv2d_171[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_175 (B  (None, None, None, 384)      1152      ['conv2d_175[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_171 (Activation  (None, None, None, 384)      0         ['batch_normalization_171[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_175 (Activation  (None, None, None, 384)      0         ['batch_normalization_175[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)         (None, None, None, 384)      442368    ['activation_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)         (None, None, None, 384)      442368    ['activation_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)         (None, None, None, 384)      442368    ['activation_175[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)         (None, None, None, 384)      442368    ['activation_175[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_16 (Aver  (None, None, None, 1280)     0         ['mixed8[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)         (None, None, None, 320)      409600    ['mixed8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_172 (B  (None, None, None, 384)      1152      ['conv2d_172[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_173 (B  (None, None, None, 384)      1152      ['conv2d_173[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_176 (B  (None, None, None, 384)      1152      ['conv2d_176[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_177 (B  (None, None, None, 384)      1152      ['conv2d_177[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)         (None, None, None, 192)      245760    ['average_pooling2d_16[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_170 (B  (None, None, None, 320)      960       ['conv2d_170[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_172 (Activation  (None, None, None, 384)      0         ['batch_normalization_172[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_173 (Activation  (None, None, None, 384)      0         ['batch_normalization_173[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_176 (Activation  (None, None, None, 384)      0         ['batch_normalization_176[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_177 (Activation  (None, None, None, 384)      0         ['batch_normalization_177[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_178 (B  (None, None, None, 192)      576       ['conv2d_178[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_170 (Activation  (None, None, None, 320)      0         ['batch_normalization_170[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)      (None, None, None, 768)      0         ['activation_172[0][0]',      \n",
      "                                                                     'activation_173[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, None, None, 768)      0         ['activation_176[0][0]',      \n",
      " )                                                                   'activation_177[0][0]']      \n",
      "                                                                                                  \n",
      " activation_178 (Activation  (None, None, None, 192)      0         ['batch_normalization_178[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)        (None, None, None, 2048)     0         ['activation_170[0][0]',      \n",
      "                                                                     'mixed9_0[0][0]',            \n",
      "                                                                     'concatenate_2[0][0]',       \n",
      "                                                                     'activation_178[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)         (None, None, None, 448)      917504    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_183 (B  (None, None, None, 448)      1344      ['conv2d_183[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_183 (Activation  (None, None, None, 448)      0         ['batch_normalization_183[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)         (None, None, None, 384)      786432    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)         (None, None, None, 384)      1548288   ['activation_183[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_180 (B  (None, None, None, 384)      1152      ['conv2d_180[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_184 (B  (None, None, None, 384)      1152      ['conv2d_184[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_180 (Activation  (None, None, None, 384)      0         ['batch_normalization_180[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_184 (Activation  (None, None, None, 384)      0         ['batch_normalization_184[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)         (None, None, None, 384)      442368    ['activation_180[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)         (None, None, None, 384)      442368    ['activation_180[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)         (None, None, None, 384)      442368    ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)         (None, None, None, 384)      442368    ['activation_184[0][0]']      \n",
      "                                                                                                  \n",
      " average_pooling2d_17 (Aver  (None, None, None, 2048)     0         ['mixed9[0][0]']              \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)         (None, None, None, 320)      655360    ['mixed9[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_181 (B  (None, None, None, 384)      1152      ['conv2d_181[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_182 (B  (None, None, None, 384)      1152      ['conv2d_182[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_185 (B  (None, None, None, 384)      1152      ['conv2d_185[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_186 (B  (None, None, None, 384)      1152      ['conv2d_186[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)         (None, None, None, 192)      393216    ['average_pooling2d_17[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_179 (B  (None, None, None, 320)      960       ['conv2d_179[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_181 (Activation  (None, None, None, 384)      0         ['batch_normalization_181[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_182 (Activation  (None, None, None, 384)      0         ['batch_normalization_182[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_185 (Activation  (None, None, None, 384)      0         ['batch_normalization_185[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " activation_186 (Activation  (None, None, None, 384)      0         ['batch_normalization_186[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_187 (B  (None, None, None, 192)      576       ['conv2d_187[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_179 (Activation  (None, None, None, 320)      0         ['batch_normalization_179[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)      (None, None, None, 768)      0         ['activation_181[0][0]',      \n",
      "                                                                     'activation_182[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, None, None, 768)      0         ['activation_185[0][0]',      \n",
      " )                                                                   'activation_186[0][0]']      \n",
      "                                                                                                  \n",
      " activation_187 (Activation  (None, None, None, 192)      0         ['batch_normalization_187[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)       (None, None, None, 2048)     0         ['activation_179[0][0]',      \n",
      "                                                                     'mixed9_1[0][0]',            \n",
      "                                                                     'concatenate_3[0][0]',       \n",
      "                                                                     'activation_187[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21802784 (83.17 MB)\n",
      "Trainable params: 21768352 (83.04 MB)\n",
      "Non-trainable params: 34432 (134.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "# Load the InceptionV3 model\n",
    "model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Print the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alinnavas/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-04-20 09:57:51,056] A new study created in memory with name: no-name-5f25f442-a26c-4918-8590-dddac2802be2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 09:57:52.428096: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-20 09:57:52.706383: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-20 09:57:55.320061: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-04-20 09:57:55.671028: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f5a5081d3d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-20 09:57:55.671052: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-04-20 09:57:55.683807: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713603475.748409    3438 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-04-20 09:57:56.160778: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:57:56.295111: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:57:59.085595: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:57:59.344507: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:02.485233: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:02.768168: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:06.511153: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:06.956914: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:08.358404: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-04-20 09:58:09.303109: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 23s 493ms/step - loss: 5.7691 - accuracy: 0.0703 - val_loss: 3.6341 - val_accuracy: 0.1094\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 3.1520 - accuracy: 0.1094 - val_loss: 2.3349 - val_accuracy: 0.0781\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.2816 - accuracy: 0.1016 - val_loss: 2.3709 - val_accuracy: 0.1094\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 2.2936 - accuracy: 0.1094 - val_loss: 2.3258 - val_accuracy: 0.1094\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 2.2812 - accuracy: 0.1406 - val_loss: 2.3194 - val_accuracy: 0.0938\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 2.2797 - accuracy: 0.0938 - val_loss: 2.3333 - val_accuracy: 0.0938\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 2.2804 - accuracy: 0.1328 - val_loss: 2.3293 - val_accuracy: 0.1094\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 2.2666 - accuracy: 0.1641 - val_loss: 2.3682 - val_accuracy: 0.1094\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 2.2571 - accuracy: 0.1719 - val_loss: 2.3243 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2733 - accuracy: 0.0859 - val_loss: 2.3941 - val_accuracy: 0.1094\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.2782 - accuracy: 0.1172 - val_loss: 2.3194 - val_accuracy: 0.0938\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2665 - accuracy: 0.0859 - val_loss: 2.3349 - val_accuracy: 0.1094\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 2.2430 - accuracy: 0.1406 - val_loss: 2.4387 - val_accuracy: 0.1094\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2749 - accuracy: 0.1406 - val_loss: 2.3422 - val_accuracy: 0.1094\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 2.2711 - accuracy: 0.0859 - val_loss: 2.3391 - val_accuracy: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:58:36,224] Trial 0 finished with value: 0.078125 and parameters: {'num_layers': 0}. Best is trial 0 with value: 0.078125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 310ms/step - loss: 3.4155 - accuracy: 0.1016 - val_loss: 2.3146 - val_accuracy: 0.1094\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.3109 - accuracy: 0.1172 - val_loss: 2.4180 - val_accuracy: 0.0781\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.6484 - accuracy: 0.1172 - val_loss: 3.0903 - val_accuracy: 0.1094\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 250ms/step - loss: 2.6533 - accuracy: 0.1562 - val_loss: 2.3036 - val_accuracy: 0.0781\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.3078 - accuracy: 0.1328 - val_loss: 2.3034 - val_accuracy: 0.1094\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2984 - accuracy: 0.1094 - val_loss: 2.3037 - val_accuracy: 0.0781\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2961 - accuracy: 0.1250 - val_loss: 2.3039 - val_accuracy: 0.0781\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 2.2945 - accuracy: 0.1406 - val_loss: 2.3042 - val_accuracy: 0.0781\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.2927 - accuracy: 0.1328 - val_loss: 2.3045 - val_accuracy: 0.0781\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 243ms/step - loss: 2.2917 - accuracy: 0.1484 - val_loss: 2.3049 - val_accuracy: 0.0781\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 2.2911 - accuracy: 0.1328 - val_loss: 2.3053 - val_accuracy: 0.0781\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2893 - accuracy: 0.1094 - val_loss: 2.3056 - val_accuracy: 0.0781\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 244ms/step - loss: 2.2875 - accuracy: 0.1328 - val_loss: 2.3061 - val_accuracy: 0.0781\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 253ms/step - loss: 2.2868 - accuracy: 0.1250 - val_loss: 2.3065 - val_accuracy: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:58:49,145] Trial 1 finished with value: 0.078125 and parameters: {'num_layers': 6}. Best is trial 0 with value: 0.078125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 298ms/step - loss: 3.4378 - accuracy: 0.0859 - val_loss: 2.3462 - val_accuracy: 0.0938\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 2.2975 - accuracy: 0.1172 - val_loss: 2.3697 - val_accuracy: 0.0938\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 2.3049 - accuracy: 0.1328 - val_loss: 2.4122 - val_accuracy: 0.1172\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 238ms/step - loss: 2.3288 - accuracy: 0.1250 - val_loss: 2.2779 - val_accuracy: 0.1250\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 240ms/step - loss: 2.2182 - accuracy: 0.1484 - val_loss: 2.2621 - val_accuracy: 0.0859\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 237ms/step - loss: 2.2042 - accuracy: 0.1719 - val_loss: 2.2433 - val_accuracy: 0.1328\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 2.1241 - accuracy: 0.1641 - val_loss: 2.2244 - val_accuracy: 0.2031\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 2.0561 - accuracy: 0.2266 - val_loss: 2.2441 - val_accuracy: 0.2578\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.9708 - accuracy: 0.3125 - val_loss: 2.2456 - val_accuracy: 0.2188\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 2.0068 - accuracy: 0.3203 - val_loss: 2.2576 - val_accuracy: 0.2188\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 2.0533 - accuracy: 0.3594 - val_loss: 2.2811 - val_accuracy: 0.1797\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 2.0237 - accuracy: 0.2422 - val_loss: 2.5109 - val_accuracy: 0.2109\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 2.0703 - accuracy: 0.2266 - val_loss: 2.3868 - val_accuracy: 0.1875\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 233ms/step - loss: 1.8907 - accuracy: 0.3594 - val_loss: 2.3406 - val_accuracy: 0.2109\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 231ms/step - loss: 1.7898 - accuracy: 0.3438 - val_loss: 2.4127 - val_accuracy: 0.2734\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 232ms/step - loss: 1.7606 - accuracy: 0.4219 - val_loss: 2.3601 - val_accuracy: 0.2422\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 241ms/step - loss: 1.5327 - accuracy: 0.4141 - val_loss: 2.3136 - val_accuracy: 0.2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:59:03,607] Trial 2 finished with value: 0.2421875 and parameters: {'num_layers': 3}. Best is trial 2 with value: 0.2421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 483ms/step - loss: 5.0290 - accuracy: 0.1250 - val_loss: 3.2121 - val_accuracy: 0.0938\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 2.5509 - accuracy: 0.1641 - val_loss: 3.0302 - val_accuracy: 0.0859\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 2.4736 - accuracy: 0.1250 - val_loss: 2.3094 - val_accuracy: 0.1094\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.2900 - accuracy: 0.1016 - val_loss: 2.3596 - val_accuracy: 0.1094\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2800 - accuracy: 0.1250 - val_loss: 3.0388 - val_accuracy: 0.1094\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.3710 - accuracy: 0.1172 - val_loss: 2.3115 - val_accuracy: 0.0938\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.3076 - accuracy: 0.1250 - val_loss: 2.3269 - val_accuracy: 0.0938\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2769 - accuracy: 0.1250 - val_loss: 2.3141 - val_accuracy: 0.0859\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 2.3357 - accuracy: 0.1484 - val_loss: 2.3178 - val_accuracy: 0.0781\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2468 - accuracy: 0.1484 - val_loss: 2.5009 - val_accuracy: 0.1094\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2996 - accuracy: 0.1562 - val_loss: 2.3154 - val_accuracy: 0.0781\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 2.2703 - accuracy: 0.1016 - val_loss: 2.3177 - val_accuracy: 0.1094\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 2.2720 - accuracy: 0.1406 - val_loss: 2.3339 - val_accuracy: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:59:25,509] Trial 3 finished with value: 0.09375 and parameters: {'num_layers': 0}. Best is trial 2 with value: 0.2421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 310ms/step - loss: 2.8931 - accuracy: 0.1328 - val_loss: 2.5353 - val_accuracy: 0.0781\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.3635 - accuracy: 0.1172 - val_loss: 6.2588 - val_accuracy: 0.0781\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 252ms/step - loss: 3.5463 - accuracy: 0.1172 - val_loss: 2.4096 - val_accuracy: 0.0781\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.5287 - accuracy: 0.1328 - val_loss: 2.3023 - val_accuracy: 0.1094\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 2.3012 - accuracy: 0.1562 - val_loss: 2.3026 - val_accuracy: 0.1094\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.3215 - accuracy: 0.1328 - val_loss: 2.3026 - val_accuracy: 0.1094\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2993 - accuracy: 0.1328 - val_loss: 2.3026 - val_accuracy: 0.1094\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 246ms/step - loss: 2.3306 - accuracy: 0.0938 - val_loss: 2.3027 - val_accuracy: 0.1094\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2976 - accuracy: 0.1094 - val_loss: 2.3028 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.3418 - accuracy: 0.1094 - val_loss: 2.3030 - val_accuracy: 0.0938\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2946 - accuracy: 0.1406 - val_loss: 2.3031 - val_accuracy: 0.0938\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 245ms/step - loss: 2.2941 - accuracy: 0.1172 - val_loss: 2.3033 - val_accuracy: 0.0938\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 247ms/step - loss: 2.2923 - accuracy: 0.1484 - val_loss: 2.3035 - val_accuracy: 0.0938\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 254ms/step - loss: 2.2914 - accuracy: 0.1328 - val_loss: 2.3037 - val_accuracy: 0.0938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:59:38,556] Trial 4 finished with value: 0.09375 and parameters: {'num_layers': 6}. Best is trial 2 with value: 0.2421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5513 - accuracy: 0.1094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 09:59:40,258] Trial 5 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 322ms/step - loss: 4.8765 - accuracy: 0.1172 - val_loss: 3.9337 - val_accuracy: 0.1641\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 3.8584 - accuracy: 0.1328 - val_loss: 4.2484 - val_accuracy: 0.0859\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 3.1367 - accuracy: 0.1719 - val_loss: 2.6884 - val_accuracy: 0.1094\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 2.5888 - accuracy: 0.0469 - val_loss: 2.3541 - val_accuracy: 0.1641\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 2.3888 - accuracy: 0.1641 - val_loss: 2.3143 - val_accuracy: 0.1016\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.2282 - accuracy: 0.1484 - val_loss: 2.3438 - val_accuracy: 0.0938\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 2.2219 - accuracy: 0.1406 - val_loss: 2.2727 - val_accuracy: 0.0938\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.1957 - accuracy: 0.1328 - val_loss: 2.2998 - val_accuracy: 0.0938\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.1852 - accuracy: 0.1250 - val_loss: 2.2836 - val_accuracy: 0.0938\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.1501 - accuracy: 0.1484 - val_loss: 2.3053 - val_accuracy: 0.1016\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.1522 - accuracy: 0.1562 - val_loss: 2.2903 - val_accuracy: 0.0938\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.1183 - accuracy: 0.1406 - val_loss: 2.2829 - val_accuracy: 0.0938\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 2.1244 - accuracy: 0.1484 - val_loss: 2.2662 - val_accuracy: 0.0938\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.1092 - accuracy: 0.1406 - val_loss: 2.2833 - val_accuracy: 0.0859\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.0602 - accuracy: 0.1641 - val_loss: 2.2930 - val_accuracy: 0.0938\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 266ms/step - loss: 2.0926 - accuracy: 0.1641 - val_loss: 2.2617 - val_accuracy: 0.0938\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 2.0822 - accuracy: 0.1406 - val_loss: 2.2571 - val_accuracy: 0.0938\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 2.0849 - accuracy: 0.1406 - val_loss: 2.3078 - val_accuracy: 0.0938\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 2.0550 - accuracy: 0.1484 - val_loss: 2.2321 - val_accuracy: 0.0781\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.0423 - accuracy: 0.1797 - val_loss: 2.2811 - val_accuracy: 0.0938\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.0295 - accuracy: 0.1641 - val_loss: 2.2874 - val_accuracy: 0.0938\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 2.0190 - accuracy: 0.1562 - val_loss: 2.2182 - val_accuracy: 0.0859\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.9788 - accuracy: 0.1719 - val_loss: 2.2739 - val_accuracy: 0.0859\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.9847 - accuracy: 0.1875 - val_loss: 2.2668 - val_accuracy: 0.0859\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.9720 - accuracy: 0.1641 - val_loss: 2.2209 - val_accuracy: 0.1094\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.9778 - accuracy: 0.1875 - val_loss: 2.2378 - val_accuracy: 0.0938\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.9525 - accuracy: 0.1484 - val_loss: 2.2520 - val_accuracy: 0.1172\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.9110 - accuracy: 0.2031 - val_loss: 2.2188 - val_accuracy: 0.1484\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 1.9206 - accuracy: 0.2266 - val_loss: 2.2182 - val_accuracy: 0.1797\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.9205 - accuracy: 0.3359 - val_loss: 2.2400 - val_accuracy: 0.1719\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.9204 - accuracy: 0.2812 - val_loss: 2.2547 - val_accuracy: 0.1953\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 1.9270 - accuracy: 0.2656 - val_loss: 2.1970 - val_accuracy: 0.2109\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.8362 - accuracy: 0.3594 - val_loss: 2.2589 - val_accuracy: 0.1953\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.8869 - accuracy: 0.3125 - val_loss: 2.2079 - val_accuracy: 0.2188\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.8689 - accuracy: 0.3438 - val_loss: 2.1844 - val_accuracy: 0.2188\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.8433 - accuracy: 0.2734 - val_loss: 2.3023 - val_accuracy: 0.2109\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.8490 - accuracy: 0.2812 - val_loss: 2.1852 - val_accuracy: 0.2109\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 262ms/step - loss: 1.8575 - accuracy: 0.3672 - val_loss: 2.1804 - val_accuracy: 0.2344\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.8007 - accuracy: 0.3359 - val_loss: 2.2853 - val_accuracy: 0.2109\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 261ms/step - loss: 1.8525 - accuracy: 0.2656 - val_loss: 2.1742 - val_accuracy: 0.2188\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.7649 - accuracy: 0.3359 - val_loss: 2.2286 - val_accuracy: 0.2109\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.7885 - accuracy: 0.3516 - val_loss: 2.2312 - val_accuracy: 0.2109\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.7745 - accuracy: 0.2344 - val_loss: 2.1470 - val_accuracy: 0.2188\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.7533 - accuracy: 0.3047 - val_loss: 2.2478 - val_accuracy: 0.2109\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 1.8081 - accuracy: 0.2578 - val_loss: 2.1979 - val_accuracy: 0.2109\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 263ms/step - loss: 1.7643 - accuracy: 0.3281 - val_loss: 2.1458 - val_accuracy: 0.2188\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.7881 - accuracy: 0.2500 - val_loss: 2.2263 - val_accuracy: 0.2188\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 1.7088 - accuracy: 0.3203 - val_loss: 2.2373 - val_accuracy: 0.2109\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 1.7577 - accuracy: 0.3438 - val_loss: 2.1006 - val_accuracy: 0.2344\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 1.7646 - accuracy: 0.3047 - val_loss: 2.1941 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 10:00:25,378] Trial 6 finished with value: 0.21875 and parameters: {'num_layers': 1}. Best is trial 2 with value: 0.2421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 330ms/step - loss: 7.1378 - accuracy: 0.1094 - val_loss: 11.6435 - val_accuracy: 0.0859\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 1s 264ms/step - loss: 4.6993 - accuracy: 0.1094 - val_loss: 2.3472 - val_accuracy: 0.0938\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 2.3044 - accuracy: 0.1172 - val_loss: 2.3027 - val_accuracy: 0.1094\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.3012 - accuracy: 0.1484 - val_loss: 2.4158 - val_accuracy: 0.1094\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.3392 - accuracy: 0.0938 - val_loss: 2.3030 - val_accuracy: 0.1094\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 2.2999 - accuracy: 0.1328 - val_loss: 2.3031 - val_accuracy: 0.1094\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.2988 - accuracy: 0.1562 - val_loss: 2.3033 - val_accuracy: 0.1094\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 257ms/step - loss: 2.2973 - accuracy: 0.1328 - val_loss: 2.3035 - val_accuracy: 0.1094\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 2.2963 - accuracy: 0.1250 - val_loss: 2.3038 - val_accuracy: 0.1094\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 256ms/step - loss: 2.2947 - accuracy: 0.1406 - val_loss: 2.4379 - val_accuracy: 0.0859\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 258ms/step - loss: 2.3157 - accuracy: 0.1406 - val_loss: 2.3044 - val_accuracy: 0.1094\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 255ms/step - loss: 2.2925 - accuracy: 0.1406 - val_loss: 2.3047 - val_accuracy: 0.1094\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 268ms/step - loss: 2.2919 - accuracy: 0.1406 - val_loss: 2.3050 - val_accuracy: 0.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 10:00:38,247] Trial 7 finished with value: 0.109375 and parameters: {'num_layers': 7}. Best is trial 2 with value: 0.2421875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 5.5720 - accuracy: 0.1328"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-20 10:00:40,602] Trial 8 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 10:00:41.737181: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_fused_impl.h:660 : UNKNOWN: CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n",
      "[W 2024-04-20 10:00:41,752] Trial 9 failed with parameters: {'num_layers': 0} because of the following error: UnknownError().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_3108/616720336.py\", line 39, in objective\n",
      "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=50, callbacks=[early_stopping, pruning_callback], verbose=1)\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.UnknownError: Graph execution error:\n",
      "\n",
      "Detected at node sequential_10/vgg16/block3_conv2/Relu defined at (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_3108/616720336.py\", line 46, in <module>\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 62, in _optimize\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 159, in _optimize_sequential\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "\n",
      "  File \"/tmp/ipykernel_3108/616720336.py\", line 39, in objective\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 398, in call\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/activations.py\", line 306, in relu\n",
      "\n",
      "  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5395, in relu\n",
      "\n",
      "CUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n",
      "\t [[{{node sequential_10/vgg16/block3_conv2/Relu}}]] [Op:__inference_train_function_39927]\n",
      "[W 2024-04-20 10:00:41,754] Trial 9 failed with value None.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_10/vgg16/block3_conv2/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3108/616720336.py\", line 46, in <module>\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 62, in _optimize\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 159, in _optimize_sequential\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n\n  File \"/tmp/ipykernel_3108/616720336.py\", line 39, in objective\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5395, in relu\n\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node sequential_10/vgg16/block3_conv2/Relu}}]] [Op:__inference_train_function_39927]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Create an Optuna study and optimize the objective function\u001b[39;00m\n\u001b[1;32m     45\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters and objective value\u001b[39;00m\n\u001b[1;32m     49\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     37\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     38\u001b[0m pruning_callback \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mintegration\u001b[38;5;241m.\u001b[39mTFKerasPruningCallback(trial, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Return the validation accuracy as the objective value\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node sequential_10/vgg16/block3_conv2/Relu defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_3108/616720336.py\", line 46, in <module>\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/study.py\", line 451, in optimize\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 62, in _optimize\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 159, in _optimize_sequential\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n\n  File \"/tmp/ipykernel_3108/616720336.py\", line 39, in objective\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 398, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 321, in call\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/activations.py\", line 306, in relu\n\n  File \"/home/alinnavas/.local/lib/python3.10/site-packages/keras/src/backend.py\", line 5395, in relu\n\nCUDNN failed to allocate the scratch space for the runner or to find a working no-scratch runner.\n\t [[{{node sequential_10/vgg16/block3_conv2/Relu}}]] [Op:__inference_train_function_39927]"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pickle\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import swish, relu,selu\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    num_layers = trial.suggest_categorical('num_layers', [31, 62, 82])\n",
    "    num_neurons = trial.suggest_int('num_neurons', 8, 10000)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "\n",
    "    # Create the MLP model with hyperparameters\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze the layers in the base model\n",
    "    for layer in base_model.layers[:-num_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "    model = Sequential()\n",
    "\n",
    "# Add the InceptionV3 base model to the new model\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_neurons, input_shape=(x_train.shape[1],)))\n",
    "    model.add(Activation(relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model with hyperparameters\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model with hyperparameters\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min', min_delta=0.001, restore_best_weights=True)\n",
    "    pruning_callback = optuna.integration.TFKerasPruningCallback(trial, 'val_loss')\n",
    "    lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='min', min_lr=learning_rate/1000)\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=150, callbacks=[early_stopping, pruning_callback,lr_on_plateau], verbose=1)\n",
    "    # Return the validation accuracy as the objective value\n",
    "    return history.history['val_accuracy'][-1]\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "sampler = optuna.samplers.TPESampler(seed=42, n_startup_trials=100)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "save_path = './opt_study/optuna_incep_spec_r0_v2_study.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "# Print the best hyperparameters and objective value\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print('Best Hyperparameters:', best_params)\n",
    "print('Best Objective Value:', best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
